{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T08:35:36.327638Z",
     "start_time": "2021-03-07T08:35:36.324636Z"
    }
   },
   "source": [
    "XGBoost ~ gridcv tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T08:35:50.477583Z",
     "start_time": "2021-03-07T08:35:50.475591Z"
    }
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T08:36:18.750399Z",
     "start_time": "2021-03-07T08:36:18.748398Z"
    }
   },
   "source": [
    "## transform_features & ~2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:02.178353Z",
     "start_time": "2021-03-13T11:47:00.543163Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pre-processing functions\n",
    "Add functions you need\n",
    "\"\"\"\n",
    "\n",
    "## Functions\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fillna(df):\n",
    "    Age_mean = df['Age'].mean()\n",
    "    Age_mode = df['Age'].mode()\n",
    "    freq = df['Embarked'].value_counts().idxmax()\n",
    "    \n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Cabin'] = df['Cabin'].str[:1]  #indexing\n",
    "    df['Age'].fillna(Age_mean, inplace=True)\n",
    "    df['Embarked'].fillna(freq, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fillna_2(df):\n",
    "    Age_mean = df['Age'].mean()\n",
    "    Age_mode = df['Age'].mode()\n",
    "    freq = df['Embarked'].value_counts().idxmax()\n",
    "    Fare_mean = df['Fare'].mean()\n",
    "    \n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Cabin'] = df['Cabin'].str[:1]  \n",
    "    df['Fare'].fillna(Fare_mean, inplace=True)\n",
    "    df['Age'].fillna(Age_mean, inplace=True)\n",
    "    df['Embarked'].fillna(freq, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "## For use\n",
    "def transform_features(df):\n",
    "    df = drop_features(df)\n",
    "    df = fillna(df)\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform_features_2(df):\n",
    "    df = drop_features(df)\n",
    "    df = fillna_2(df)\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T08:36:33.828891Z",
     "start_time": "2021-03-07T08:36:33.826899Z"
    }
   },
   "source": [
    "## get_outlier & transform_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:02.183354Z",
     "start_time": "2021-03-13T11:47:02.179353Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_outlier(df=None, column=None, weight=1.5):\n",
    "    #Object\n",
    "    var1 = df[column]\n",
    "    \n",
    "    #25%, 75%  #numpy value ---> percentage\n",
    "    quantile_25 = np.percentile(var1.values,25)\n",
    "    quantile_75 = np.percentile(var1.values,75)\n",
    "    \n",
    "    #iqr\n",
    "    iqr = quantile_75 - quantile_25\n",
    "    iqr_weight = iqr *weight\n",
    "    lowest_val = quantile_25 - iqr_weight\n",
    "    highest_val = quantile_75 + iqr_weight\n",
    "    \n",
    "    #conditions\n",
    "    outlier_index = var1[(var1<lowest_val)|(var1>highest_val)].index\n",
    "    #outlier_index = var1[(var1<lowest_val)].index\n",
    "    #outlier_index = var1[(var1>highest_val)].index\n",
    "    \n",
    "    print(\"<Outliers>\")\n",
    "    print(\"highest_val :\", highest_val)\n",
    "    print(\"lowest_val :\", lowest_val)\n",
    "    print(\"len :\",len(outlier_index), end='\\n\\n')    \n",
    "    return outlier_index, highest_val, lowest_val\n",
    "\n",
    "\n",
    "def transform_outlier(df=None, column=None, weight=1.5):\n",
    "    x, var1, var2 = get_outlier(df=df, column=column, weight=weight)\n",
    "    #df[column].iloc[x] = x  #both\n",
    "    df[column].iloc[x] = var1  #highest index\n",
    "    #df[column].iloc[x] = var2  #lowest index\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T08:38:00.038017Z",
     "start_time": "2021-03-07T08:38:00.036026Z"
    }
   },
   "source": [
    "# Set Trainset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:02.571431Z",
     "start_time": "2021-03-13T11:47:02.185345Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Outliers>\n",
      "highest_val : 134.9032\n",
      "lowest_val : -95.9928\n",
      "len : 34\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      891 non-null    int64  \n",
      " 1   Age         891 non-null    float64\n",
      " 2   SibSp       891 non-null    int64  \n",
      " 3   Parch       891 non-null    int64  \n",
      " 4   Fare        891 non-null    float64\n",
      " 5   Sex_male    891 non-null    uint8  \n",
      " 6   Cabin_B     891 non-null    uint8  \n",
      " 7   Cabin_C     891 non-null    uint8  \n",
      " 8   Cabin_D     891 non-null    uint8  \n",
      " 9   Cabin_E     891 non-null    uint8  \n",
      " 10  Cabin_F     891 non-null    uint8  \n",
      " 11  Cabin_G     891 non-null    uint8  \n",
      " 12  Cabin_N     891 non-null    uint8  \n",
      " 13  Cabin_T     891 non-null    uint8  \n",
      " 14  Embarked_Q  891 non-null    uint8  \n",
      " 15  Embarked_S  891 non-null    uint8  \n",
      "dtypes: float64(2), int64(3), uint8(11)\n",
      "memory usage: 44.5 KB\n"
     ]
    }
   ],
   "source": [
    "# module import \n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data load \n",
    "df = pd.read_csv(\"C:\\\\Users\\\\icecr\\\\OneDrive\\\\CSV_file\\\\titanic\\\\train.csv\")\n",
    "#df = pd.read_csv(\"C:\\\\Users\\\\82103\\\\OneDrive\\\\CSV_file\\\\titanic\\\\train.csv\")  #for notebook\n",
    "\n",
    "# Devide feature & label\n",
    "y_df = df['Survived']\n",
    "X_df = df.drop('Survived', axis=1)\n",
    "\n",
    "# Apply pre-processing func\n",
    "X_df = transform_features(X_df)\n",
    "X_df = transform_outlier(df=X_df, column='Fare', weight=4.5)\n",
    "\n",
    "X_df.info()\n",
    "\n",
    "#pd.set_option('display.max_rows',500)  #row 출력개수 설정(자동생략 option off 기능)\n",
    "#X_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:02.578432Z",
     "start_time": "2021-03-13T11:47:02.572432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      891 non-null    int64  \n",
      " 1   Age         891 non-null    float64\n",
      " 2   SibSp       891 non-null    int64  \n",
      " 3   Parch       891 non-null    int64  \n",
      " 4   Fare        891 non-null    float64\n",
      " 5   Sex_male    891 non-null    uint8  \n",
      " 6   Cabin_B     891 non-null    uint8  \n",
      " 7   Cabin_C     891 non-null    uint8  \n",
      " 8   Cabin_D     891 non-null    uint8  \n",
      " 9   Cabin_E     891 non-null    uint8  \n",
      " 10  Cabin_F     891 non-null    uint8  \n",
      " 11  Cabin_G     891 non-null    uint8  \n",
      " 12  Cabin_N     891 non-null    uint8  \n",
      " 13  Embarked_Q  891 non-null    uint8  \n",
      " 14  Embarked_S  891 non-null    uint8  \n",
      "dtypes: float64(2), int64(3), uint8(10)\n",
      "memory usage: 43.6 KB\n"
     ]
    }
   ],
   "source": [
    "# delete Cabin_T ---> testset don't has Cabin_T, trainset has 1 data\n",
    "X_df = X_df.drop(['Cabin_T'], axis=1)\n",
    "X_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T08:39:36.254254Z",
     "start_time": "2021-03-07T08:39:36.251263Z"
    }
   },
   "source": [
    "# Testing:trainset\n",
    "## without tuning tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:02.597437Z",
     "start_time": "2021-03-13T11:47:02.579433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset : (712, 15)\n",
      "testset : (179, 15)\n",
      "\n",
      "trainset label ratio\n",
      "0    0.616573\n",
      "1    0.383427\n",
      "Name: Survived, dtype: float64\n",
      "\n",
      "testset label ratio\n",
      "0    0.614525\n",
      "1    0.385475\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Devide trainset:testset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=0)\n",
    "\n",
    "# Verify label ratio \n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "\n",
    "print('trainset :', X_train.shape)\n",
    "print('testset :',X_test.shape, end='\\n\\n')\n",
    "\n",
    "print(\"trainset label ratio\")\n",
    "print(y_train.value_counts()/train_cnt, end='\\n\\n')\n",
    "\n",
    "print(\"testset label ratio\")\n",
    "print(y_test.value_counts()/test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:03.170565Z",
     "start_time": "2021-03-13T11:47:02.597437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_Acc : 0.7821\n",
      "dt_roc_auc : 0.7580\n",
      "\n",
      "rf_Acc : 0.8101\n",
      "rf_roc_auc : 0.8870\n",
      "\n",
      "lr_Acc : 0.8156\n",
      "lr_roc_auc : 0.8689\n",
      "\n",
      "[20:47:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "xgb_Acc : 0.8547\n",
      "xgb_roc_auc : 0.8709\n"
     ]
    }
   ],
   "source": [
    "## Models\n",
    "\n",
    "# Import module\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "# Make object : classifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "\n",
    "#DecisionTree\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print('dt_Acc : {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('dt_roc_auc : {0:.4f}'.format(roc_auc_score(y_test, dt_clf.predict_proba(X_test)[:,1])))\n",
    "print('')\n",
    "\n",
    "\n",
    "#RandomForest\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('rf_Acc : {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('rf_roc_auc : {0:.4f}'.format(roc_auc_score(y_test, rf_clf.predict_proba(X_test)[:,1])))\n",
    "print('')\n",
    "\n",
    "\n",
    "#LogisticRegression\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('lr_Acc : {0:.4f}'.format(accuracy_score(y_test, lr_pred)))\n",
    "print('lr_roc_auc : {0:.4f}'.format(roc_auc_score(y_test, lr_clf.predict_proba(X_test)[:,1])))\n",
    "print('')\n",
    "\n",
    "\n",
    "##XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb_clf = XGBClassifier(n_estimators=100)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "           \n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "xgb_acc_score = accuracy_score(y_test, xgb_clf.predict(X_test))\n",
    "print('')\n",
    "print('xgb_Acc : {0:.4f}'.format(xgb_acc_score))\n",
    "print('xgb_roc_auc : {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T08:40:34.446193Z",
     "start_time": "2021-03-07T08:40:34.443192Z"
    }
   },
   "source": [
    "## GridCV : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:17.571795Z",
     "start_time": "2021-03-13T11:47:03.171566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    6.5s remaining:    6.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:47:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { reg_lamda, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   14.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs...\n",
       "             n_jobs=-1,\n",
       "             param_grid={'booster': ['gbtree'], 'colsample_bytree': [1],\n",
       "                         'eval_metric': ['error'], 'learning_rate': [0.1, 0.05],\n",
       "                         'max_depth': [3], 'min_child_weight': [1],\n",
       "                         'min_split_loss': [0], 'n_estimators': [100, 10000],\n",
       "                         'objective': ['binary:logistic'], 'reg_alpha': [0],\n",
       "                         'reg_lamda': [1], 'scale_pos_weight': [1],\n",
       "                         'silent': [0], 'subsample': [1]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "params = {#general params\n",
    "          'booster':['gbtree'],  #default=gbtree, other:gblinear\n",
    "          'silent':[0],  #default=0, other:1(=silent)    \n",
    "          \n",
    "          #Booster params\n",
    "          'learning_rate':[0.1, 0.05],  #default=0.1\n",
    "          'n_estimators':[100, 1000],  #default=100\n",
    "          'min_child_weight':[1],  #default=1\n",
    "          'min_split_loss':[0],  #default=0  #gamma\n",
    "          'max_depth':[3],  #default=3\n",
    "          'subsample':[1],  #default=1\n",
    "          'colsample_bytree':[1],  #default=1\n",
    "          'reg_lamda':[1],  #default=1\n",
    "          'reg_alpha':[0],  #default=0\n",
    "          'scale_pos_weight':[1],  #default=1\n",
    "    \n",
    "          #Training task params    \n",
    "          'objective':['binary:logistic'],  #default=logistic, other:index top\n",
    "          'eval_metric':['error']  #default=rmse|error  #ohter : mae, logloss, merror, mlogloss\n",
    "          }\n",
    "\n",
    "\n",
    "xgb_clf = XGBClassifier()\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_clf, \n",
    "                        param_grid=params, \n",
    "                        cv=5,\n",
    "                        scoring='accuracy',  #default=accuracy  #options : roc_auc, f1\n",
    "                        refit=True,\n",
    "                        n_jobs=-1, \n",
    "                        verbose=1\n",
    "                       )\n",
    "\n",
    "xgb_grid.fit(X_df, y_df)\n",
    "\n",
    "\n",
    "## [Early stopping code]\n",
    "# gridcv.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='auc',\n",
    "#           eval_set=[(X_train, y_train), (X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:17.576796Z",
     "start_time": "2021-03-13T11:47:17.572795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score : 0.8260686711443098\n",
      "\n",
      "Best parameters :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'colsample_bytree': 1,\n",
       " 'eval_metric': 'error',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 1,\n",
       " 'min_split_loss': 0,\n",
       " 'n_estimators': 100,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lamda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'silent': 0,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Result\n",
    "print('Best score :', xgb_grid.best_score_, end='\\n\\n')\n",
    "print('Best parameters :')\n",
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:17.597801Z",
     "start_time": "2021-03-13T11:47:17.577797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'booster': 'gbtree', 'colsample_bytree': 1, '...</td>\n",
       "      <td>0.826069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'booster': 'gbtree', 'colsample_bytree': 1, '...</td>\n",
       "      <td>0.820444</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'booster': 'gbtree', 'colsample_bytree': 1, '...</td>\n",
       "      <td>0.812604</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'booster': 'gbtree', 'colsample_bytree': 1, '...</td>\n",
       "      <td>0.808097</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "0  {'booster': 'gbtree', 'colsample_bytree': 1, '...         0.826069   \n",
       "2  {'booster': 'gbtree', 'colsample_bytree': 1, '...         0.820444   \n",
       "3  {'booster': 'gbtree', 'colsample_bytree': 1, '...         0.812604   \n",
       "1  {'booster': 'gbtree', 'colsample_bytree': 1, '...         0.808097   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "2                2  \n",
       "3                3  \n",
       "1                4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result details\n",
    "cv_res_df = pd.DataFrame(xgb_grid.cv_results_)\n",
    "cv_res_df.sort_values(by=['rank_test_score'], inplace=True)\n",
    "cv_res_df[['params', 'mean_test_score', 'rank_test_score']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T06:47:58.808733Z",
     "start_time": "2021-03-07T06:47:58.806732Z"
    }
   },
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:17.611804Z",
     "start_time": "2021-03-13T11:47:17.598801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# data load \n",
    "df_test = pd.read_csv(\"C:\\\\Users\\\\icecr\\\\OneDrive\\\\CSV_file\\\\titanic\\\\test.csv\")\n",
    "#df_test = pd.read_csv(\"C:\\\\Users\\\\82103\\\\OneDrive\\\\CSV_file\\\\titanic\\\\test.csv\")  #for notebook\n",
    "\n",
    "test_id = df_test.PassengerId\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:17.632810Z",
     "start_time": "2021-03-13T11:47:17.612804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Outliers>\n",
      "highest_val : 137.7189\n",
      "lowest_val : -98.3231\n",
      "len : 23\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      418 non-null    int64  \n",
      " 1   Age         418 non-null    float64\n",
      " 2   SibSp       418 non-null    int64  \n",
      " 3   Parch       418 non-null    int64  \n",
      " 4   Fare        418 non-null    float64\n",
      " 5   Sex_male    418 non-null    uint8  \n",
      " 6   Cabin_B     418 non-null    uint8  \n",
      " 7   Cabin_C     418 non-null    uint8  \n",
      " 8   Cabin_D     418 non-null    uint8  \n",
      " 9   Cabin_E     418 non-null    uint8  \n",
      " 10  Cabin_F     418 non-null    uint8  \n",
      " 11  Cabin_G     418 non-null    uint8  \n",
      " 12  Cabin_N     418 non-null    uint8  \n",
      " 13  Embarked_Q  418 non-null    uint8  \n",
      " 14  Embarked_S  418 non-null    uint8  \n",
      "dtypes: float64(2), int64(3), uint8(10)\n",
      "memory usage: 20.5 KB\n"
     ]
    }
   ],
   "source": [
    "X_df_test = transform_features_2(df_test)\n",
    "X_df_test = transform_outlier(df=X_df_test, column='Fare', weight=4.5)\n",
    "\n",
    "X_df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:17.638811Z",
     "start_time": "2021-03-13T11:47:17.633809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "#y_hat = xgb_clf.predict(X_df_test)  #XGB_raw(not tuning)\n",
    "\n",
    "y_hat = xgb_grid.predict(X_df_test)  #GridCV tuned\n",
    "print(len(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T11:47:17.653814Z",
     "start_time": "2021-03-13T11:47:17.640811Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId':test_id, 'Survived':y_hat})\n",
    "submission.to_csv(\"c:\\\\Users\\\\icecr\\\\OneDrive\\\\CSV_file\\\\titanic\\\\Sub25.csv\", index=False)\n",
    "\n",
    "##Verify label & id\n",
    "# print(y_hat)\n",
    "# for  i,a  in  enumerate(y_hat):\n",
    "#     print (str(i+892) + ',' + str(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
