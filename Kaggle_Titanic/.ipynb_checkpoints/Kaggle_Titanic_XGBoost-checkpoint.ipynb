{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T07:25:42.061282Z",
     "start_time": "2021-03-06T07:25:42.059281Z"
    }
   },
   "source": [
    "# Load data & details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T07:29:56.501774Z",
     "start_time": "2021-03-06T07:29:56.498773Z"
    }
   },
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T14:47:17.766838Z",
     "start_time": "2021-05-01T14:47:17.723828Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\icecr\\\\OneDrive\\\\CSV_file\\\\titanic\\\\train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f46d021e13dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# data load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\icecr\\\\OneDrive\\\\CSV_file\\\\titanic\\\\train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;31m#df = pd.read_csv(\"C:\\\\Users\\\\82103\\\\OneDrive\\\\CSV_file\\\\titanic\\\\train.csv\")  #for notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m         )\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_1\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m             )\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\icecr\\\\OneDrive\\\\CSV_file\\\\titanic\\\\train.csv'"
     ]
    }
   ],
   "source": [
    "# module import \n",
    "import Func_T1  #Func_sets(custom)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "import copy\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data load \n",
    "#df = pd.read_csv(\"C:\\\\Users\\\\icecr\\\\OneDrive\\\\CSV_file\\\\titanic\\\\train.csv\")\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\82103\\\\OneDrive\\\\CSV_file\\\\titanic\\\\train.csv\")  #for notebook\n",
    "\n",
    "pd.set_option('display.max_rows',50)  #row 출력개수 설정(자동생략 option off 기능)\n",
    "pd.set_option('display.max_columns',20)  #column 출력개수 설정(자동생략 option off 기능)\n",
    "df[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T07:32:39.308735Z",
     "start_time": "2021-03-06T07:32:39.306734Z"
    }
   },
   "source": [
    "## details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T14:47:34.491872Z",
     "start_time": "2021-05-01T14:47:34.467867Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify column and types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T14:48:30.139900Z",
     "start_time": "2021-05-01T14:48:30.130899Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label coulumn class ratio\n",
    "print(\"<Label Class Ratio>\")\n",
    "df['Survived'].value_counts() /df.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value count : X\n",
    "print(\"<Column : Pclass> \\n\", df['Sex'].value_counts(), end='\\n\\n')\n",
    "print(\"<Column : Name> \\n\", df['Name'].value_counts(), end='\\n\\n')\n",
    "print(\"<Column : Sex> \\n\", df['Sex'].value_counts(), end='\\n\\n')\n",
    "print(\"<Column : Age> \\n\", df['Age'].value_counts(), end='\\n\\n')\n",
    "print(\"<Column : SibSp> \\n\", df['SibSp'].value_counts(), end='\\n\\n')\n",
    "print(\"<Column : Parch> \\n\", df['Parch'].value_counts(), end='\\n\\n')\n",
    "print(\"<Column : Ticket> \\n\", df['Ticket'].value_counts(), end='\\n\\n')\n",
    "print(\"<Column : Fare> \\n\", df['Fare'].value_counts(), end='\\n\\n')\n",
    "print(\"<Column : Embarked> \\n\", df['Embarked'].value_counts(), end='\\n\\n')\n",
    "print(\"<Column : Cabin> \\n\", df['Cabin'].value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T14:48:32.822948Z",
     "start_time": "2021-05-01T14:48:32.803945Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify null data\n",
    "print(\"<Isnull>\")\n",
    "print(df.isnull().sum())\n",
    "print('')\n",
    "print(\"Total :\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T07:50:14.330588Z",
     "start_time": "2021-03-06T07:50:14.328588Z"
    }
   },
   "source": [
    "# Pre-processing & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T08:05:41.202905Z",
     "start_time": "2021-03-06T08:05:41.200914Z"
    },
    "tags": []
   },
   "source": [
    "## Exchange NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = Func_T1.fillna_int(df, method=\"mean\", c1=\"Age\")\n",
    "df2 = Func_T1.fillna_str(df2, method=\"mode\", c1=\"Embarked\")\n",
    "df2 = Func_T1.fillna_str2(df2, value='N', c1=\"Cabin\")\n",
    "print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T08:31:53.755762Z",
     "start_time": "2021-03-07T08:31:53.753770Z"
    }
   },
   "source": [
    "## Analysis : Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T09:44:24.764798Z",
     "start_time": "2021-03-07T09:44:24.761799Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "corr=df2.corr()\n",
    "sns.heatmap(corr, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T09:44:24.769799Z",
     "start_time": "2021-03-07T09:44:24.766799Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(data=df2['Fare'], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T09:44:24.773801Z",
     "start_time": "2021-03-07T09:44:24.771800Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import module\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Pclass ~ Survived\n",
    "#sns.barplot(x='Sex', y='Survived', data=df_2)\n",
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T09:44:24.778803Z",
     "start_time": "2021-03-07T09:44:24.774801Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Survived ~ Age\n",
    "\n",
    "def get_category(age):\n",
    "    cat = ''\n",
    "    if age <= -1 : cat='Unknown'\n",
    "    elif age <= 5: cat='Baby'\n",
    "    elif age <= 12: cat='Child'\n",
    "    elif age <= 18: cat='Teenager'\n",
    "    elif age <= 25: cat='Student'\n",
    "    elif age <= 35: cat='Young Adult'\n",
    "    elif age <= 60: cat='Adult'\n",
    "    else: cat='Elderly'\n",
    "        \n",
    "    return cat\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "group_names=['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
    "\n",
    "df2['Age_cat'] = df2['Age'].apply(lambda x : get_category(x))\n",
    "sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=df2, order=group_names)\n",
    "df2.drop('Age_cat', axis=1, inplace=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T08:05:23.202301Z",
     "start_time": "2021-03-06T08:05:23.200308Z"
    }
   },
   "source": [
    "## Drop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = Func_T1.drop_features(df2, c1=\"PassengerId\", c2=\"Name\", c3=\"Ticket\", c4=\"Cabin\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-10T11:17:14.592346Z",
     "start_time": "2021-03-10T11:17:14.431Z"
    },
    "tags": []
   },
   "source": [
    "## Get outlier & Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = Func_T1.transform_outlier(dataframe=df3, method=\"both\", column=\"Fare\", weight=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout outlier\n",
    "Func_T1.transform_outlier(dataframe=df4, method=\"both\", column=\"Fare\", weight=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T08:30:04.969280Z",
     "start_time": "2021-03-07T08:30:04.967288Z"
    }
   },
   "source": [
    "## Get_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T10:02:24.913400Z",
     "start_time": "2021-03-07T10:02:24.896395Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dummy column \n",
    "df5 = copy.deepcopy(df4)\n",
    "df5 = pd.get_dummies(df5, drop_first=True)  #drop_first help modeling better**\n",
    "df5\n",
    "\n",
    "#delete Cabin_T ---> testset don't has Cabin_T, trainset has 1 data\n",
    "#df5 = df5.drop(['Cabin_T'], axis=1)\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T02:22:12.805413Z",
     "start_time": "2021-03-07T02:22:12.800422Z"
    }
   },
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T08:33:01.090519Z",
     "start_time": "2021-03-07T08:33:01.088509Z"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module \n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# verify xgboost version\n",
    "print(xgb.__version__)  #1.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T10:03:44.010157Z",
     "start_time": "2021-03-07T10:03:44.002158Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Devide feature & label\n",
    "y_df = df5['Survived']\n",
    "X_df = df5.drop('Survived', axis=1)\n",
    "\n",
    "# Devide trainset:testset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=0)\n",
    "\n",
    "# Verify label ratio \n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "\n",
    "print('trainset :', X_train.shape)\n",
    "print('testset :',X_test.shape, end='\\n\\n')\n",
    "\n",
    "print(\"trainset label ratio\")\n",
    "print(y_train.value_counts()/train_cnt, end='\\n\\n')\n",
    "\n",
    "print(\"trainset label ratio\")\n",
    "print(y_test.value_counts()/test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with non-gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T10:03:48.644919Z",
     "start_time": "2021-03-07T10:03:48.218833Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Models\n",
    "\n",
    "# Import module\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "# Make object : classifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "\n",
    "#DecisionTree\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print('dt_Acc : {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('dt_roc_auc : {0:.4f}'.format(roc_auc_score(y_test, dt_clf.predict_proba(X_test)[:,1])))\n",
    "print('')\n",
    "\n",
    "\n",
    "#RandomForest\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('rf_Acc : {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('rf_roc_auc : {0:.4f}'.format(roc_auc_score(y_test, rf_clf.predict_proba(X_test)[:,1])))\n",
    "print('')\n",
    "\n",
    "\n",
    "#LogisticRegression\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('lr_Acc : {0:.4f}'.format(accuracy_score(y_test, lr_pred)))\n",
    "print('lr_roc_auc : {0:.4f}'.format(roc_auc_score(y_test, lr_clf.predict_proba(X_test)[:,1])))\n",
    "print('')\n",
    "\n",
    "\n",
    "##XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb_clf = XGBClassifier(n_estimators=100)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "           \n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "xgb_acc_score = accuracy_score(y_test, xgb_clf.predict(X_test))\n",
    "print('')\n",
    "print('xgb_Acc : {0:.4f}'.format(xgb_acc_score))\n",
    "print('xgb_roc_auc : {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T09:45:02.807028Z",
     "start_time": "2021-03-07T09:45:02.804027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature importance = visualization\n",
    "\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,8))\n",
    "plot_importance(xgb_clf, ax=ax, max_num_features=12, height=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridCV : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T10:10:51.412616Z",
     "start_time": "2021-03-07T10:09:27.777845Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import modules \n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "params = {#general params\n",
    "          'booster':['gbtree'],  #default=gbtree, other:gblinear\n",
    "          'silent':[0],  #default=0, other:1(=silent)    \n",
    "          \n",
    "          #Booster params\n",
    "          'learning_rate':[0.1, 0.05, 0.01],  #default=0.1\n",
    "          'n_estimators':[100,150,200,500],  #default=100\n",
    "          'min_child_weight':[1,2],  #default=1\n",
    "          'min_split_loss':[0,10,50],  #default=0  #gamma\n",
    "          'max_depth':[3,4,5],  #default=3\n",
    "          'subsample':[1],  #default=1\n",
    "          'colsample_bytree':[0.8,1],  #default=1\n",
    "          'reg_lamda':[1],  #default=1\n",
    "          'reg_alpha':[0],  #default=0\n",
    "          'scale_pos_weight':[1],  #default=1\n",
    "    \n",
    "          #Training task params    \n",
    "          'objective':['binary:logistic'],  #default=logistic, other:index top\n",
    "          'eval_metric':['error']  #default=rmse|error  #ohter : mae, logloss, merror, mlogloss\n",
    "          }\n",
    "\n",
    "\n",
    "xgb_clf_t = XGBClassifier()\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_clf_t, \n",
    "                        param_grid=params, \n",
    "                        cv=5, \n",
    "                        scoring='accuracy',  #default=accuracy  #options : roc_auc, f1\n",
    "                        refit=True,\n",
    "                        n_jobs=-1, \n",
    "                        verbose=0\n",
    "                       )\n",
    "\n",
    "xgb_grid.fit(X_df, y_df)\n",
    "\n",
    "\n",
    "## [Early stopping code]\n",
    "# gridcv.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='auc',\n",
    "#           eval_set=[(X_train, y_train), (X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T10:10:58.105452Z",
     "start_time": "2021-03-07T10:10:58.101451Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Result\n",
    "\n",
    "print('Best score :', xgb_grid.best_score_, end='\\n\\n')\n",
    "print('Best parameters :')\n",
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T10:11:04.613079Z",
     "start_time": "2021-03-07T10:11:04.603077Z"
    }
   },
   "outputs": [],
   "source": [
    "#Result details\n",
    "\n",
    "cv_res_df = pd.DataFrame(xgb_grid.cv_results_)\n",
    "cv_res_df.sort_values(by=['rank_test_score'], inplace=True)\n",
    "cv_res_df[['params', 'mean_test_score', 'rank_test_score']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load \n",
    "#df_test = pd.read_csv(\"C:\\\\Users\\\\icecr\\\\OneDrive\\\\CSV_file\\\\titanic\\\\test.csv\")\n",
    "df_test = pd.read_csv(\"C:\\\\Users\\\\82103\\\\OneDrive\\\\CSV_file\\\\titanic\\\\test.csv\")  #for notebook\n",
    "\n",
    "pd.set_option('display.max_rows',50)  #row 출력개수 설정(자동생략 option off 기능)\n",
    "pd.set_option('display.max_columns',20)  #column 출력개수 설정(자동생략 option off 기능)\n",
    "df_test[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify column and types\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Value count : X\n",
    "# print(\"<Column : Pclass> \\n\", df_test['Sex'].value_counts(), end='\\n\\n')\n",
    "# print(\"<Column : Name> \\n\", df_test['Name'].value_counts(), end='\\n\\n')\n",
    "# print(\"<Column : Sex> \\n\", df_test['Sex'].value_counts(), end='\\n\\n')\n",
    "# print(\"<Column : Age> \\n\", df_test['Age'].value_counts(), end='\\n\\n')\n",
    "# print(\"<Column : SibSp> \\n\", df_test['SibSp'].value_counts(), end='\\n\\n')\n",
    "# print(\"<Column : Parch> \\n\", df_test['Parch'].value_counts(), end='\\n\\n')\n",
    "# print(\"<Column : Ticket> \\n\", df_test['Ticket'].value_counts(), end='\\n\\n')\n",
    "# print(\"<Column : Fare> \\n\", df_test['Fare'].value_counts(), end='\\n\\n')\n",
    "# print(\"<Column : Embarked> \\n\", df_test['Embarked'].value_counts(), end='\\n\\n')\n",
    "# print(\"<Column : Cabin> \\n\", df_test['Cabin'].value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify null data\n",
    "print(\"<Isnull>\")\n",
    "print(df_test.isnull().sum())\n",
    "print('')\n",
    "print(\"Total :\", df_test.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = Func_T1.fillna_int(df_test, method=\"mean\", c1=\"Age\")\n",
    "df_test = Func_T1.fillna_str2(df_test, value='N', c1=\"Cabin\")\n",
    "df_test = Func_T1.fillna_int(df_test, method='mean', c1=\"Fare\")\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get outlier & Exchange\n",
    "\n",
    "df_test = Func_T1.transform_outlier(dataframe=df_test, method=\"both\", column=\"Fare\", weight=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkout outlier\n",
    "\n",
    "Func_T1.transform_outlier(dataframe=df4, method=\"both\", column=\"Fare\", weight=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save id data for submission\n",
    "test_id = df_test.PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features\n",
    "df_test = Func_T1.drop_features(df_test, c1=\"PassengerId\", c2=\"Name\", c3=\"Ticket\", c4=\"Cabin\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummy column \n",
    "\n",
    "df_test = copy.deepcopy(df_test)\n",
    "df_test = pd.get_dummies(df_test, drop_first=True)  #drop_first help modeling better**\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X_df_test & check out\n",
    "\n",
    "X_df_test = df_test\n",
    "X_df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_hat = xgb_clf.predict(X_df_test)  #XGB_raw(not tuning)\n",
    "y_hat = xgb_grid.predict(X_df_test)  #GridCV tuned\n",
    "print(len(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save submission in local path\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId':test_id, 'Survived':y_hat})\n",
    "#submission.to_csv(\"C:\\\\Users\\\\icecr\\\\Desktop\\\\downloads\\\\Sub001.csv\", index=False)\n",
    "submission.to_csv(\"C:\\\\Users\\\\82103\\\\Desktop\\\\downloads\\\\Sub001.csv\", index=False) For notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log\n",
    "\n",
    "print(y_hat)\n",
    "for  i,a  in  enumerate(y_hat):\n",
    "    print (str(i+892) + ',' + str(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_1",
   "language": "python",
   "name": "ml_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
